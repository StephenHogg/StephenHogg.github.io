---
layout: post
title: "How to gather a bunch of evidence and then completely ignore it"
---

Oh my god this happens all the time I swear. If you're working in machine learning then it is unavoidable that you work in the presence of uncertainty. This isn't such a bad thing, but how we think as humans sometimes works against us when dealing with uncertainty. This post will look at what goes wrong and more importantly, how to spot it so you can do something about it.

Everyone's different[^1], so maybe this advice won't work for everyone. But that's fine.

# What's the story?[^2]

One obvious way to get caught is in a [narrative fallacy](https://wiki.lesswrong.com/wiki/Narrative_fallacy). And fair enough. Machine learning models can be big complicated things, so knowing what's going on in them is an active field of research in its own right, not just an onerous task for the practitioner. The easiest way to catch yourself succumbing to a narrative fallacy is if you ever say _"I know what's going on here"_, or words to that effect to yourself. This is because if you're saying that you're focussing on the rare delight of being right, as opposed to sticking to the task of working out what you still don't know.

I don't think any less of anyone for thinking like this to be honest, large parts of an ML person's job is being wrong. Wanting a win every now and then is only human. Problem is, a lot of the time when you think you've got it all sorted out, you're actually shooting yourself in the foot at that very moment. It can really be a dirty, difficult job. So keep an eye on yourself if you find yourself desperate for a breakthrough, you might accidentally join the dots in a way that allows you to hallucinate one. Turn it up to 11 if you find yourself deliberately glossing over any piece of evidence at your disposal because it conflicts with your story.[^3] 

[AutoML seems like a good way around this problem, but in my opinion it's an iron law that in any situation a sufficiently innovative and eager person can always find a way to shoot themselves in the foot. So it isn't a way around these pitfalls, in my view]()

The other textbook-definition narrative fallacy I see _absolutely everywhere_ consists of pretending your neural network functions the same way as a human brain does. When it inevitably doesn't, you immediately don't know what to do because your whole frame of reference just became invalid. Stop doing this! Not only does this involve proceeding in a way that shies away from the complexity of the task at hand, but also for free you find yourself completely at sea the second you need to be the opposite. Of course there are plenty of very, very smart people who use the human brain analogy to educate others about how neural nets work, but that doesn't mean you should use that framework to build one yourself. 




* Narrative fallacy
* Dunning Kruger effect
* 
* What can you do about it?
*


[^1]: of course
[^2]: ...[morning glory](https://www.youtube.com/watch?v=Wm54XyLwBAk)
[^3]: Being able to spot yourself doing this and act is the hard part. In all seriousness, have a look at some cognitive behavioural therapy material. It's not just for depressed people, it can help you work more effectively with your internal monologue and state of mind and not let this stuff slide through.
